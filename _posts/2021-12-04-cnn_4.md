---
layout: single
title: "Softmax 이해하기"
author_profile: true
excerpt: "logistic regression softmax, cross entrophy"
categories:
    - CNN
---

### 컨볼루션을 통해 얻는 값은 무엇인가

CNN에서 컨볼루션과 풀링 Batch Normalization 등의 과정을 통해 최종 FCN (fully conected layer)를 통해 생성 된 값들은 **실수값**을 가지게 된다. 그 실수 값을 통해 우리는 모델의 예측이 무엇인지 알고 싶다. 하지만 모델의 예측은 1 또는 0 의 값을 가지는게 아니라 실수값을 가지기 때문에, 우리는 이 값을 확률로 표현하고 싶은 것이다. 

### 왜 확률로 얻고 싶은가

그것이 직관적이기 때문이다. 무한히 클 수 있는 실수값들의 나열로는 상대적 해석이 불가하다. 예를 들어서 사과에 대한 값이 1790987가 나오고 배에 대한 값이  12390 나왔다면 어떻게 해석해야 할까? 직관적으로 이 결과를 [0,1] 사이로 값을 가지는 정규화를 통해 상대적인 해석이 가능하도록 하고 싶은 것이다.

### softmax는 어떻게 작동하는가

![softmax_layer](/assets/images/softmax_layer.PNG)

위의 그림에서 보면, Softmax 함수는 각 클래스별 로지스틱 회귀 함수를 적용하는 것과 같다. 원리는 **로지스틱 회귀 함수**를 적용하는 것이고, 이것을 **다중 클래스로 확장한 것이 Softmax 함수**인 것이다. 여기서 주의 깊게 살펴봐야 할 것은 각 클래스별 판별은 A 클래스 이냐 B 클래스 이냐가 아니라(A or B?), A 클래스 이냐 아니냐의(A or Not?) 문제인 것이다. 

### 소프트맥스의 가정

소프트맥스 함수는 하나의 input이 **하나의 클래스에만 속한다고 가정한다.** 그러나 데이터에 따라서 이런 경우가 아닌 경우도 있을 수 있다. 이러한 경우에는 소프트맥스를 사용할 수 없다. 이 경우 다중 로지스틱 회귀에 의존해야 한다. 예를들어 개, 고양이, 사자 동물을 분류하는 Task에서 만약 한 이미지에 개, 고양이, 사자가 모두 포함되어 있는 경우에는 **다중 로지스틱 회귀(Multinomial Logistic regression)**를 사용해야 한다.

### 소프트맥스의 변형

Full softmax는 가능한 모든 클래스에 대해서 확률을 계산하는 것을 의미한다. 하지만 softmax가 클래스가 적을 때는 효율적이지만, **클래스가 많은 경우에는 상당한 비용**이 발생하게 된다. 그래서 **Candiate Sampling** 기법을 활용할 수가 있다. 예를들어 사과인지 배인지에 대한 관심이 있는 경우 Positive는 사과와 배라는 클래스로 보고, **Negative 클래스에 대해서는 남은 나머지 클래스 전부를 택하는 것이 아니라 샘플링을 통해서 Negative 클래스를 설정하는 방법이다.** 여기서는 과일이 아닌 동물과 같은 클래스를 제외시켜 Negative 클래스를 설정하여 확률값을 계산할 수 있다.

### Cost Fuction ( Cross-entrophy )

Softmax 를 통해서 최종적으로 예측하는 모델을 만들었다. (예측한 레이블 값을 얻었다) 그러면 이제 예측값과 실제 레이블을 비교하여 학습이 되도록 비용함수를 설계해야 한다. 기본적으로 비용함수는 Cross Entrophy를 사용한다.  Cross Entropht가 잘 작동하기 때문인데, 어떻게 작동하는 지 살펴보도록 하자.

![cross_entrophy](/assets/images/cross_entrophy.png)

위 그림을 보면, 1번이 올바르게 예측한 경우 (True) 이고 2번이 예측이 틀린 경우 (False) 이다. 올바르게 예측한 경우는 Cost 가 0을 가지게 되지만, 잘못 예측한 경우에는 무한대 값의 비용함수 값을 가지게 되는 구조이다. 즉 틀렸을 경우에만 패널티를 더해주는 구조인 셈이다. 여러 개의 클래스인 경우의는 전체 클래스에 대한 비용함수를 구하여 모두 합하고 클래스 개수 N 개로나누면 멀티 클래스에 대한 비용함수를 구할 수 있다. 비용함수가 정의가 되면, 마지막으로 Gradient decent 방식을 이용해 최소화한다.

### Reference

[https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax?hl=ko](https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax?hl=ko)
https://www.youtube.com/watch?v=jMU9G5WEtBc