---
layout: single
title: "MLOps를 위한 ML 워크플로우"
author_profile: true
excerpt: "MLOps, Work flow, Life cycle "
categories:
    - MLOps
---

ML의 Work Flow를 살펴보고, 각 단계에서 MLOps 위해 필요한 것들을 생각해보자.

## Work Flow

- Data ingestion
- Data validation
- Data preprocessing
- Model training
- Model analysis and validation
- Model deployment



#### Data ingestion

ingestion 단계는 DB에 저장된 데이터를 ETL 과 같은 오퍼레이션을 통해 데이터를 가쟈오는 단계이다. 



#### Data validation

validation 단계는 DB로부터 가져온 데이터를 검증하는 단계이다. 검증된 데이터 분포가 아닌 이상치 데이터를 감지하는 등의 작업을 통하여 데이터를 검증한다. 데이터 과학자가 정해놓은 통계치들을 이용한다. (mean, std ..)



#### Data preprocessing

효과적인 학습을 위해 데이터를 전처리하는 단계이다. ( normalization..)



#### Model training

최종적으로 만들어진 데이터를 이용하여 학습을 하는 단계이다. 하이퍼파라미터 조정등 튜닝이 필요할 수 있다.



#### Model analysis and validation

학습된 모델을 평가하고 분석하는 단계이다. 



#### Model deployment

모델을 운영서버에 배포하는 단계이다. 



## 머신러닝 파이프라인을 위한 도구

#### 작업 명령을 내려줄 수 있는 오케스트레이션 도구

**Data ingestion 단계에서부터 Model Training 까지** 자동화시킬 수 있어야 한다. 만약 데이터가 기간을 정하여 한번씩 입수가 된다면, 데이터가 입수 되었을 때, 일련의 작업이 진행되어야 할 것이다. 각각의 단계는 하나의(또는 여러개) python file 실행을 통해서 작업을 진행할 수 있을 것이다. 그러면 이전 작업의 output이 다음단계의 input으로 제공되어야 한다. 일련의 처리 작업을 자동으로 실행 시켜줄 수 있는 툴이 필요하다. 



#### 하이퍼파라미터를 자동으로 찾아주는 도구

Training 단계에서는 데이터 셋의 구성을 달리한 여러 가지 학습이 있을 수도 있으며, 동일한 데이터 셋 구성에서 하이퍼파리미터 변화를 준 다양한 학습 모델이 생성될 수 있다. 이때 자동으로 최적의 하이퍼파라미터를 찾아주는 도구가 필요하거나, 그렇지 않다면 데이터 과학자가 하이퍼파라미터 값을 직접 설정하여 학습을 할 때, 반복적 학습이 가능하도록 해야한다.



#### 실험결과를 대시보드를 통해 쉽게 비주얼라이제이션 할 수 있는 도구

Training과 함께 Model analysis and validation 단계에서 이루어지는 학습결과 및 테스트 결과를 쉽게 볼 수 있어야 하고, 이를 팀원과 공유가 수월해야 한다.



#### 데이터 과학자가 선택한 모델을 운영서버에 자동으로 배포시킬 수 있는 도구

Model analysis and validation 을 통해 배포를 결정한 모델에 대해서 배포가 자동으로 이루어 질 수 있게 개발되어야 한다. 



#### Tracking을 위한 메타데이터 저장 도구

Tracking을 위해서는 데이터베이스에 데이터를 저장해야한다. 어떠 데이터로 학습이 된 모델인지, 성능은 얼마였는지, 배포가 된 모델인지 아닌지 등. Tracking은 **Model training ~ deployment 단계**에 필요하다.












